{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd198a77-c31a-4b86-a6f5-bfb84d6e8dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"author: sarah konrad, data+ 2023\n",
    "supervised text clustering!\n",
    "\"\"\"\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#all functions written here\n",
    "def gettexts(folder):\n",
    "    texts = []\n",
    "    #list of lists of strings, each text broken up into individual token strings\n",
    "    tokenized = []\n",
    "    #list of texts as a continuous string\n",
    "    textnames = []\n",
    "    for file in os.listdir(folder):\n",
    "        path = os.path.join(folder,file)\n",
    "        name = os.path.basename(file)\n",
    "        f = open(path,'r', encoding=\"utf-8\")\n",
    "        data = f.read()\n",
    "        textnames.append(name)\n",
    "        texts.append(data)\n",
    "        f.close()\n",
    "    for text in texts:\n",
    "        #tokenize by white space\n",
    "        words = text.strip().split(' ')\n",
    "        tokenized.append(words)\n",
    "    return [tokenized, texts, textnames]\n",
    "\n",
    "def get_relevant_ids(dictionary, terms_list):\n",
    "    id_list = []\n",
    "    existing_files = []\n",
    "    for file in os.scandir(r\"/hpc/group/datap2023ecbc/lemmatized_without_stop\"):\n",
    "        name  = os.path.basename(file).split(\".\")[0]\n",
    "        existing_files.append(name)\n",
    "    for key in dictionary.keys():\n",
    "        if key in existing_files:\n",
    "                for value in dictionary.get(key):\n",
    "                    for terms in terms_list:\n",
    "                        if value in terms: \n",
    "                            id_list.append(key)\n",
    "    return id_list\n",
    "\n",
    "def move_relevant_ids(id_list):\n",
    "    for file in os.scandir(r\"/hpc/group/datap2023ecbc/lemmatized_without_stop\"):\n",
    "        name = os.path.basename(file).split(\".\")[0]\n",
    "        if name in id_list:\n",
    "            with open(file, encoding=\"utf-8\") as EPextracted:\n",
    "                #remember to put the correct pathway for output and input! based off of what you are trying\n",
    "                #to understand!\n",
    "                with open(os.path.join(r\"/hpc/group/datap2023ecbc/supervised_class_new\", name), 'w+') as lowerFile:\n",
    "                    data = EPextracted.read()\n",
    "                    lowerFile.write(data.lower())\n",
    "\n",
    "#use on the EP_availabletexts spreadsheet\n",
    "def get_metadata_dict_for_final(sheet):\n",
    "    relevantIDs = get_relevant_ids(keyword_dict_prelim, targets)\n",
    "    metadata_dict = {}\n",
    "    with open(sheet, encoding='utf-8') as metadata_sheet:\n",
    "        reader = csv.reader(metadata_sheet, delimiter=',')\n",
    "        for line in reader:\n",
    "            key = line[0]\n",
    "            values = line[6]\n",
    "            values = values.split('--')\n",
    "            values = [value.strip() for value in values]\n",
    "            if key in relevantIDs:\n",
    "                metadata_dict[key] = values\n",
    "    return metadata_dict\n",
    "\n",
    "def get_metadata_dict_prelim(sheet):\n",
    "    metadata_dict = {}\n",
    "    with open(sheet, encoding='utf-8') as metadata_sheet:\n",
    "        reader = csv.reader(metadata_sheet, delimiter=',')\n",
    "        for line in reader:\n",
    "            key = line[0]\n",
    "            values = line[6]\n",
    "            values = values.split('--')\n",
    "            values = [value.strip() for value in values]\n",
    "            metadata_dict[key] = values\n",
    "    return metadata_dict\n",
    "\n",
    "def add_texts_to_supervised_set(keyword_dict, idlist, what_people): \n",
    "    #to add texts to the metadata_dict\n",
    "    for id in idlist: \n",
    "        keyword_dict[id] = what_people\n",
    "    move_relevant_ids(idlist)\n",
    "            \n",
    "#specify what folder you want to do supervised classification on\n",
    "\n",
    "\n",
    "all_texts =  gettexts('/hpc/group/datap2023ecbc/supervised_class_new')\n",
    "tcp_ids = all_texts[2]\n",
    "texts = all_texts[1]\n",
    "tfidf = TfidfVectorizer(min_df=2, sublinear_tf=True)\n",
    "result = tfidf.fit_transform(texts)\n",
    "readable_results = pd.DataFrame(result.toarray(), index=all_texts[2], columns=tfidf.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "41ebacc6-232a-40cd-b17b-7c0bbdc93c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9018\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "#i added too many neither texts --> i think maybe testing and training with less/ more targeted texts could be better?\n",
    "#where should i put guyana texts\n",
    "keyword_dict_prelim = get_metadata_dict_prelim('EP_availableTexts_1590-1639 - availabletexts.csv')\n",
    "print(len(keyword_dict_prelim))\n",
    "\n",
    "virginia_terms = [\"Virginia\", \"Indians of North America\", \"Raleigh's Roanoke colonies, 1584-1590\", \n",
    "     \"Description and travel. Virginia\", \"Early works to 1800. Virginia\", \"17th century. Virginia\", \"Lotteries\", 'America', 'Virginia.']\n",
    "spanish_terms = ['Early works to 1800. Spain', 'Spain', 'Early works to 1800. Inquisition','National characteristics, Spanish', 'Controversial literature. Spain',\n",
    "     'Infanta of Spain, 1566-1633.', 'Margarita,', 'Canary Islands', 'Spanish dynasty, 1580-1640.', 'Spain. Spain']\n",
    "african_terms = ['Congo (Brazzaville)', 'Africa', 'Africa, North', 'Early works to 1800. Morocco', 'Early works to 1800. Africa, West', 'Gambia River', 'Africa, Northwest']\n",
    "ireland_terms = ['Ireland', 'Social life and customs. Ireland', 'Ulster (Ireland)', 'History. Ireland', \"Tyrone's Rebellion, 1579-1603\", \"Tyrone, Hugh O'Neill,\", 'Ireland.', \n",
    "      'New description of Ireland. Catholic Church'] \n",
    "portuguese_terms = []\n",
    "guyana_terms = ['Guyana']\n",
    "\n",
    "#will reducing it even more help? \n",
    "virginia_reduced = ['Virginia']\n",
    "spanish_reduced = ['Spain']\n",
    "ireland_reduced = ['Ireland']\n",
    "african_reduced = ['Africa', 'Congo (Brazzaville)', 'Early works to 1800. Africa, West', \n",
    "                   'Africa, West', 'Gambia River', ]\n",
    "guyana_reduced = ['Guyana']\n",
    "#targets = [virginia_terms, spanish_terms, african_terms, ireland_terms, portuguese_terms, guyana_terms]\n",
    "targets = [virginia_reduced, spanish_reduced, african_reduced, ireland_reduced, guyana_reduced]\n",
    "\n",
    "id_list = get_relevant_ids(keyword_dict_prelim, targets)\n",
    "move_relevant_ids(id_list)\n",
    "\n",
    "keyword_dict = get_metadata_dict_for_final('EP_availableTexts_1590-1639 - availabletexts.csv')\n",
    "\n",
    "indentured_ids = []\n",
    "\n",
    "\n",
    "print(len(keyword_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73ddc69d-3716-4cdf-baa3-40d7738d33f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#metadata keywords! sorted by region/group of people being investigated\n",
    "comp_virginia_terms = [\"Virginia\", \"Indians of North America\", \"Raleigh's Roanoke colonies, 1584-1590\", \n",
    "    \"Colonial period, ca. 1600-1775\", \"Description and travel. Virginia\", \"ca. 1500-1542. Florida\",\n",
    "    \"Early works to 1800. Colonies\", \"Early works to 1800. Virginia\", \"17th century. Virginia\", \"Lotteries\", 'America', 'Tobacco', 'Early works to 1800. Tobacco', \n",
    "    'Tobacco industry', 'Early works to 1800. Tobacco industry', 'Virginia.']\n",
    "comp_spanish_terms = ['Early works to 1800. Spain', 'Philip III, 1598-1621', 'Spain', 'Early works to 1800. Inquisition', 'Wars of Independence, 1556-1648',\n",
    "    'National characteristics, Spanish', 'King of Spain, 1527-1598', 'Philip II, 1556-1598', 'Flores, Battle of, 1591', 'Privateering', 'Controversial literature. Spain'\n",
    "    'St. Alban College(Valladolid, Spain)', 'Jesuits', 'Delgadillo de Avellaneda, Bernaldino. Drake, Francis,', 'Cadiz Expedition, 1596',\n",
    "     'Infanta of Spain, 1566-1633.', 'Margarita,', 'Canary Islands', 'Spanish dynasty, 1580-1640.', 'Gibraltar', 'Spain. Spain', 'Sovereign (1598-1621 : Philip III)']\n",
    "comp_african_terms = ['Congo (Brazzaville)', 'Africa', 'Africa, North', 'Early works to 1800. Morocco', 'Middle East',\n",
    "    'Stuarts, 1603-1714. Africa, North', 'Early works to 1800. Africa, West', 'Gambia River', 'Africa, Northwest', 'Charles I, 1625-1649. Algeria', 'Africa.']\n",
    "comp_ireland_terms = ['Early works to 1800. Lisburn (Northern Ireland)', 'Ireland', \"Tyrone's Rebellion, 1579-1603\", 'Early works to 1800. Ireland',\n",
    "    'History, Military. Ireland', 'Catholics', 'Ulster (Ireland)', 'History. Ireland', 'Ireland. Ireland', 'Early works to 1800. Catholics',\n",
    "    'New description of Ireland. Catholic Church','Rich, Barnabe, 1540?-1617.', 'Social life and customs. Ireland', \"Tyrone, Hugh O'Neill,\",\n",
    "     'Church of Ireland', 'Dublin.', 'Early works to 1800. Cork (Ireland)', 'Early works to 1800. Royal supremacy (Church of England)', 'Falkland, Henry Cary,',\n",
    "    'Viscount, d. 1633. Ireland', 'Cork (Ireland)', 'Fire, 1622', 'Liturgy. Church of Ireland', 'Ireland.', 'Poetry. Ballads, Irish', \n",
    "    \"O'Dogherty, Cahir,\", 'Malone, William, 1586-1656.']\n",
    "#portuguese_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "20519ad3-bd1a-488b-9205-910649c08ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Spanish': 52, 'Virginia': 26, 'Ireland': 25, 'African': 3})\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "#targets counts relevant texts in the entire corpus\n",
    "targets = []\n",
    "#tcp_ids is a list of all texts that are in one of the target categories based off their metadata\n",
    "tcp_ids = set([])\n",
    "\n",
    "for key in keyword_dict.keys():\n",
    "    keywords = keyword_dict.get(key)\n",
    "    if any(k in virginia_terms for k in keywords):\n",
    "        targets.append('Virginia')\n",
    "        tcp_ids.add(key)\n",
    "    elif any(k in spanish_terms for k in keywords):\n",
    "        targets.append('Spanish')\n",
    "        tcp_ids.add(key)\n",
    "    elif any(k in ireland_terms for k in keywords):\n",
    "        targets.append(\"Ireland\")\n",
    "        tcp_ids.add(key)\n",
    "    elif any(k in african_terms for k in keywords):\n",
    "        targets.append(\"African\")\n",
    "        tcp_ids.add(key)\n",
    "    else:\n",
    "        targets.append('Neither')\n",
    "        tcp_ids.add(key)\n",
    "\n",
    "print(Counter(targets))\n",
    "print(len(tcp_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94836e4c-6f7f-472c-9d87-6739ec06576b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.4166666666666667\n",
      "\n",
      "Results of this run:\n",
      "\n",
      "TCP ID | Actual Classfication | Predicted Classification\n",
      "A19758 | Ireland | Spanish\n",
      "A12211 | Spanish | Spanish\n",
      "A02059 | Spanish | Spanish\n",
      "A12677 | Spanish | Spanish\n",
      "A71313 | Ireland | Spanish\n",
      "A04095 | Virginia | Spanish\n",
      "B14927 | Ireland | Spanish\n",
      "A19312 | Virginia | Spanish\n",
      "A04104 | Spanish | Spanish\n",
      "A12466 | Spanish | Spanish\n",
      "A00983 | Ireland | Spanish\n",
      "A13959 | Ireland | Spanish\n",
      "A04125 | Virginia | Spanish\n",
      "B15717 | Spanish | Spanish\n",
      "A08440 | Ireland | Spanish\n",
      "A04494 | Virginia | Spanish\n",
      "A09559 | African | Spanish\n",
      "A21682 | Spanish | Spanish\n",
      "A04070 | Ireland | Spanish\n",
      "A22749 | Virginia | Ireland\n",
      "A02681 | Spanish | Spanish\n",
      "A72336 | Spanish | Spanish\n",
      "A04079 | Ireland | Ireland\n",
      "A08110 | Ireland | Spanish\n",
      "A01503 | Spanish | Spanish\n",
      "A67920 | Virginia | Spanish\n",
      "A73131 | Spanish | Spanish\n",
      "A69361 | Spanish | Spanish\n",
      "A18465 | African | Spanish\n",
      "A04581 | Virginia | Spanish\n",
      "A11791 | Virginia | Spanish\n",
      "A14803 | Spanish | Spanish\n",
      "A04083 | Spanish | Ireland\n",
      "A73762 | Spanish | Spanish\n",
      "A14519 | Spanish | Spanish\n",
      "A20838 | Virginia | Spanish\n",
      "A19439 | Virginia | Spanish\n",
      "A04106 | Spanish | Spanish\n",
      "A04102 | Ireland | Spanish\n",
      "A00209 | Spanish | Spanish\n",
      "A22436 | Ireland | Spanish\n",
      "A14958 | Virginia | Spanish\n",
      "B14268 | Spanish | Spanish\n",
      "A21067 | Ireland | Spanish\n",
      "B11752 | Virginia | Spanish\n",
      "A22156 | Spanish | Spanish\n",
      "A21877 | Virginia | Spanish\n",
      "A06083 | Virginia | Spanish\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(readable_results, targets, test_size=0.45, random_state=42)\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs', penalty='none', class_weight='balanced')\n",
    "clf = lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# evaluate accuracy\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred, normalize=True, sample_weight=None))\n",
    "print()\n",
    "print(\"Results of this run:\\n\")\n",
    "print(\"TCP ID | Actual Classfication | Predicted Classification\")\n",
    "for title, real, predicted in zip(X_test.index, y_test, y_pred):\n",
    "    print(f\"{title} | {real} | {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f6c1c02-2656-484c-ab2f-8a171af9729d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.375\n",
      "\n",
      "Results of this run:\n",
      "\n",
      "TCP ID | Actual Classfication | Predicted Classification\n",
      "A19758 | Ireland | Spanish\n",
      "A12211 | Spanish | Spanish\n",
      "A02059 | Spanish | Spanish\n",
      "A12677 | Spanish | Spanish\n",
      "A71313 | Ireland | Spanish\n",
      "A04095 | Virginia | Ireland\n",
      "B14927 | Ireland | Spanish\n",
      "A19312 | Virginia | Spanish\n",
      "A04104 | Spanish | Virginia\n",
      "A12466 | Spanish | Spanish\n",
      "A00983 | Ireland | Spanish\n",
      "A13959 | Ireland | Spanish\n",
      "A04125 | Virginia | Spanish\n",
      "B15717 | Spanish | Spanish\n",
      "A08440 | Ireland | Spanish\n",
      "A04494 | Virginia | Spanish\n",
      "A09559 | African | Spanish\n",
      "A21682 | Spanish | Virginia\n",
      "A04070 | Ireland | Spanish\n",
      "A22749 | Virginia | Ireland\n",
      "A02681 | Spanish | Spanish\n",
      "A72336 | Spanish | Spanish\n",
      "A04079 | Ireland | Ireland\n",
      "A08110 | Ireland | Spanish\n",
      "A01503 | Spanish | Spanish\n",
      "A67920 | Virginia | Virginia\n",
      "A73131 | Spanish | Spanish\n",
      "A69361 | Spanish | Virginia\n",
      "A18465 | African | Spanish\n",
      "A04581 | Virginia | Spanish\n",
      "A11791 | Virginia | Spanish\n",
      "A14803 | Spanish | Spanish\n",
      "A04083 | Spanish | Ireland\n",
      "A73762 | Spanish | Spanish\n",
      "A14519 | Spanish | Spanish\n",
      "A20838 | Virginia | Spanish\n",
      "A19439 | Virginia | Spanish\n",
      "A04106 | Spanish | Spanish\n",
      "A04102 | Ireland | Virginia\n",
      "A00209 | Spanish | Spanish\n",
      "A22436 | Ireland | Spanish\n",
      "A14958 | Virginia | Spanish\n",
      "B14268 | Spanish | Spanish\n",
      "A21067 | Ireland | Virginia\n",
      "B11752 | Virginia | Spanish\n",
      "A22156 | Spanish | Spanish\n",
      "A21877 | Virginia | Spanish\n",
      "A06083 | Virginia | Spanish\n"
     ]
    }
   ],
   "source": [
    "#what about a naive bayes classifier? \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(readable_results, targets, test_size=0.45, random_state=42)\n",
    "gb = GaussianNB()\n",
    "clf = gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# evaluate accuracy\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred, normalize=True, sample_weight=None))\n",
    "print()\n",
    "print(\"Results of this run:\\n\")\n",
    "print(\"TCP ID | Actual Classfication | Predicted Classification\")\n",
    "for title, real, predicted in zip(X_test.index, y_test, y_pred):\n",
    "    print(f\"{title} | {real} | {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1cb89d95-4490-4a55-a980-8f57618868b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.375\n",
      "\n",
      "Results of this run:\n",
      "\n",
      "TCP ID | Actual Classfication | Predicted Classification\n",
      "A19758 | Ireland | Spanish\n",
      "A12211 | Spanish | Spanish\n",
      "A02059 | Spanish | Spanish\n",
      "A12677 | Spanish | Ireland\n",
      "A71313 | Ireland | Spanish\n",
      "A04095 | Virginia | Spanish\n",
      "B14927 | Ireland | Spanish\n",
      "A19312 | Virginia | Spanish\n",
      "A04104 | Spanish | Ireland\n",
      "A12466 | Spanish | Spanish\n",
      "A00983 | Ireland | Spanish\n",
      "A13959 | Ireland | Spanish\n",
      "A04125 | Virginia | Spanish\n",
      "B15717 | Spanish | Spanish\n",
      "A08440 | Ireland | Spanish\n",
      "A04494 | Virginia | Spanish\n",
      "A09559 | African | Spanish\n",
      "A21682 | Spanish | Spanish\n",
      "A04070 | Ireland | Ireland\n",
      "A22749 | Virginia | Spanish\n",
      "A02681 | Spanish | Spanish\n",
      "A72336 | Spanish | Spanish\n",
      "A04079 | Ireland | Ireland\n",
      "A08110 | Ireland | Ireland\n",
      "A01503 | Spanish | Spanish\n",
      "A67920 | Virginia | Ireland\n",
      "A73131 | Spanish | Spanish\n",
      "A69361 | Spanish | Spanish\n",
      "A18465 | African | Spanish\n",
      "A04581 | Virginia | Spanish\n",
      "A11791 | Virginia | Spanish\n",
      "A14803 | Spanish | Spanish\n",
      "A04083 | Spanish | Spanish\n",
      "A73762 | Spanish | Ireland\n",
      "A14519 | Spanish | Virginia\n",
      "A20838 | Virginia | Spanish\n",
      "A19439 | Virginia | Spanish\n",
      "A04106 | Spanish | Ireland\n",
      "A04102 | Ireland | Spanish\n",
      "A00209 | Spanish | Spanish\n",
      "A22436 | Ireland | Spanish\n",
      "A14958 | Virginia | Spanish\n",
      "B14268 | Spanish | Spanish\n",
      "A21067 | Ireland | Spanish\n",
      "B11752 | Virginia | Spanish\n",
      "A22156 | Spanish | Spanish\n",
      "A21877 | Virginia | Spanish\n",
      "A06083 | Virginia | Spanish\n"
     ]
    }
   ],
   "source": [
    "#k-nearest neighbors?\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#ask giugni about k-nearest neighbor \n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(readable_results, targets, test_size=0.45, random_state=42)\n",
    "clf = knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# evaluate accuracy\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred, normalize=True, sample_weight=None))\n",
    "print()\n",
    "print(\"Results of this run:\\n\")\n",
    "print(\"TCP ID | Actual Classfication | Predicted Classification\")\n",
    "for title, real, predicted in zip(X_test.index, y_test, y_pred):\n",
    "    print(f\"{title} | {real} | {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23faed-c969-4f6a-b23c-225704fcb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and move subcorpuses \n",
    "def move_subcorpus(id_list):\n",
    "    for file in os.scandir(r\"/hpc/group/datap2023ecbc/lemmatized_without_stop\"):\n",
    "        name = os.path.basename(file).split(\".\")[0]\n",
    "        if name in id_list:\n",
    "            with open(file, encoding=\"utf-8\") as EPextracted:\n",
    "                #remember to put the correct pathway for output and input! based off of what you are trying\n",
    "                #to understand!\n",
    "                with open(os.path.join(r\"/hpc/group/datap2023ecbc/virginia_subcorpus\", name), 'w+') as lowerFile:\n",
    "                    data = EPextracted.read()\n",
    "                    lowerFile.write(data.lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
