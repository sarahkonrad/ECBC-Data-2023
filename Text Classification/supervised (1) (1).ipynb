{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd198a77-c31a-4b86-a6f5-bfb84d6e8dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"author: sarah konrad, data+ 2023\n",
    "supervised text clustering!\n",
    "\"\"\"\n",
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#all functions written here\n",
    "def gettexts(folder):\n",
    "    texts = []\n",
    "    #list of lists of strings, each text broken up into individual token strings\n",
    "    tokenized = []\n",
    "    #list of texts as a continuous string\n",
    "    textnames = []\n",
    "    for file in os.listdir(folder):\n",
    "        path = os.path.join(folder,file)\n",
    "        name = os.path.basename(file)\n",
    "        f = open(path,'r', encoding=\"utf-8\")\n",
    "        data = f.read()\n",
    "        textnames.append(name)\n",
    "        texts.append(data)\n",
    "        f.close()\n",
    "    for text in texts:\n",
    "        #tokenize by white space\n",
    "        words = text.strip().split(' ')\n",
    "        tokenized.append(words)\n",
    "    return [tokenized, texts, textnames]\n",
    "\n",
    "def get_relevant_ids(dictionary):\n",
    "    id_list = []\n",
    "    existing_files = []\n",
    "    for file in os.scandir(r\"/hpc/group/datap2023ecbc/supervised_class_NotAccurate\"):\n",
    "        name  = os.path.basename(file).split(\".\")[0]\n",
    "        existing_files.append(name)\n",
    "    for key in dictionary.keys():\n",
    "        if key in existing_files:\n",
    "            id_list.append(key)\n",
    "    return id_list\n",
    "\n",
    "def move_relevant_ids(id_list):\n",
    "    for file in os.scandir(r\"/hpc/group/datap2023ecbc/lemmatized_without_stop\"):\n",
    "        name = os.path.basename(file).split(\".\")[0]\n",
    "        if name in id_list:\n",
    "            with open(file, encoding=\"utf-8\") as EPextracted:\n",
    "                #remember to put the correct pathway for output and input! based off of what you are trying\n",
    "                #to understand!\n",
    "                with open(os.path.join(r\"/hpc/group/datap2023ecbc/supervised_class_new\", name), 'w+') as lowerFile:\n",
    "                    data = EPextracted.read()\n",
    "                    lowerFile.write(data.lower())\n",
    "\n",
    "#use on the EP_availabletexts spreadsheet\n",
    "#for some reason this file mismatch keeps happening --> why?\n",
    "def get_metadata_dict_for_final(sheet):\n",
    "    relevantIDs = get_relevant_ids(keyword_dict_prelim)\n",
    "    metadata_dict = {}\n",
    "    with open(sheet, encoding='utf-8') as metadata_sheet:\n",
    "        reader = csv.reader(metadata_sheet, delimiter=',')\n",
    "        for line in reader:\n",
    "            key = line[0]\n",
    "            values = line[6]\n",
    "            values = values.split('--')\n",
    "            values = [value.strip() for value in values]\n",
    "            if key in relevantIDs:\n",
    "                metadata_dict[key] = values\n",
    "    return metadata_dict\n",
    "\n",
    "def get_metadata_dict_prelim(sheet):\n",
    "    metadata_dict = {}\n",
    "    with open(sheet, encoding='utf-8') as metadata_sheet:\n",
    "        reader = csv.reader(metadata_sheet, delimiter=',')\n",
    "        for line in reader:\n",
    "            key = line[0]\n",
    "            values = line[6]\n",
    "            values = values.split('--')\n",
    "            values = [value.strip() for value in values]\n",
    "            metadata_dict[key] = values\n",
    "    return metadata_dict\n",
    "\n",
    "def add_texts_to_supervised_set(keyword_dict, idlist, what_people): \n",
    "    #to add texts to the metadata_dict\n",
    "    for id in idlist: \n",
    "        keyword_dict[id] = what_people\n",
    "    move_relevant_ids(idlist)\n",
    "            \n",
    "#specify what folder you want to do supervised classification on\n",
    "\n",
    "\n",
    "all_texts =  gettexts('/hpc/group/datap2023ecbc/supervised_class_NotAccurate')\n",
    "tcp_ids = all_texts[2]\n",
    "texts = all_texts[1]\n",
    "tfidf = TfidfVectorizer(min_df=2, sublinear_tf=True)\n",
    "result = tfidf.fit_transform(texts)\n",
    "readable_results = pd.DataFrame(result.toarray(), index=all_texts[2], columns=tfidf.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ebacc6-232a-40cd-b17b-7c0bbdc93c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9018\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "#i added too many neither texts --> i think maybe testing and training with less/ more targeted texts could be better?\n",
    "#where should i put guyana texts\n",
    "keyword_dict_prelim = get_metadata_dict_prelim('EP_availableTexts_1590-1639 - availabletexts.csv')\n",
    "print(len(keyword_dict_prelim))\n",
    "\n",
    "virginia_terms = [\"Virginia\", \"Indians of North America\", \"Raleigh's Roanoke colonies, 1584-1590\", \n",
    "     \"Description and travel. Virginia\", \"Early works to 1800. Virginia\", \"17th century. Virginia\", \"Lotteries\", 'America', 'Virginia.']\n",
    "spanish_terms = ['Early works to 1800. Spain', 'Spain', 'Early works to 1800. Inquisition','National characteristics, Spanish', 'Controversial literature. Spain',\n",
    "     'Infanta of Spain, 1566-1633.', 'Margarita,', 'Canary Islands', 'Spanish dynasty, 1580-1640.', 'Spain. Spain']\n",
    "african_terms = ['Congo (Brazzaville)', 'Africa', 'Africa, North', 'Early works to 1800. Morocco', 'Early works to 1800. Africa, West', 'Gambia River', 'Africa, Northwest']\n",
    "ireland_terms = ['Ireland', 'Social life and customs. Ireland', 'Ulster (Ireland)', 'History. Ireland', \"Tyrone's Rebellion, 1579-1603\", \"Tyrone, Hugh O'Neill,\", 'Ireland.', \n",
    "      'New description of Ireland. Catholic Church'] \n",
    "portuguese_terms = []\n",
    "guyana_terms = ['Guyana']\n",
    "\n",
    "\n",
    "#will reducing it even more help? \n",
    "virginia_reduced = ['Virginia']\n",
    "spanish_reduced = ['Spain']\n",
    "ireland_reduced = ['Ireland']\n",
    "african_reduced = ['Africa', 'Congo (Brazzaville)', 'Early works to 1800. Africa, West', \n",
    "                   'Africa, West', 'Gambia River', ]\n",
    "guyana_reduced = ['Guyana']\n",
    "targets = [virginia_terms, spanish_terms, african_terms, ireland_terms, portuguese_terms, guyana_terms]\n",
    "#targets = [virginia_reduced, spanish_reduced, african_reduced, ireland_reduced, guyana_reduced]\n",
    "\n",
    "\n",
    "keyword_dict = get_metadata_dict_for_final('EP_availableTexts_1590-1639 - availabletexts.csv')\n",
    "\n",
    "indentured_ids = []\n",
    "\n",
    "\n",
    "print(len(keyword_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ddc69d-3716-4cdf-baa3-40d7738d33f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#metadata keywords! sorted by region/group of people being investigated\n",
    "comp_virginia_terms = [\"Virginia\", \"Indians of North America\", \"Raleigh's Roanoke colonies, 1584-1590\", \n",
    "    \"Colonial period, ca. 1600-1775\", \"Description and travel. Virginia\", \"ca. 1500-1542. Florida\",\n",
    "    \"Early works to 1800. Colonies\", \"Early works to 1800. Virginia\", \"17th century. Virginia\", \"Lotteries\", 'America', 'Tobacco', 'Early works to 1800. Tobacco', \n",
    "    'Tobacco industry', 'Early works to 1800. Tobacco industry', 'Virginia.']\n",
    "comp_spanish_terms = ['Early works to 1800. Spain', 'Philip III, 1598-1621', 'Spain', 'Early works to 1800. Inquisition', 'Wars of Independence, 1556-1648',\n",
    "    'National characteristics, Spanish', 'King of Spain, 1527-1598', 'Philip II, 1556-1598', 'Flores, Battle of, 1591', 'Privateering', 'Controversial literature. Spain'\n",
    "    'St. Alban College(Valladolid, Spain)', 'Jesuits', 'Delgadillo de Avellaneda, Bernaldino. Drake, Francis,', 'Cadiz Expedition, 1596',\n",
    "     'Infanta of Spain, 1566-1633.', 'Margarita,', 'Canary Islands', 'Spanish dynasty, 1580-1640.', 'Gibraltar', 'Spain. Spain', 'Sovereign (1598-1621 : Philip III)']\n",
    "comp_african_terms = ['Congo (Brazzaville)', 'Africa', 'Africa, North', 'Early works to 1800. Morocco', 'Middle East',\n",
    "    'Stuarts, 1603-1714. Africa, North', 'Early works to 1800. Africa, West', 'Gambia River', 'Africa, Northwest', 'Charles I, 1625-1649. Algeria', 'Africa.']\n",
    "comp_ireland_terms = ['Early works to 1800. Lisburn (Northern Ireland)', 'Ireland', \"Tyrone's Rebellion, 1579-1603\", 'Early works to 1800. Ireland',\n",
    "    'History, Military. Ireland', 'Catholics', 'Ulster (Ireland)', 'History. Ireland', 'Ireland. Ireland', 'Early works to 1800. Catholics',\n",
    "    'New description of Ireland. Catholic Church','Rich, Barnabe, 1540?-1617.', 'Social life and customs. Ireland', \"Tyrone, Hugh O'Neill,\",\n",
    "     'Church of Ireland', 'Dublin.', 'Early works to 1800. Cork (Ireland)', 'Early works to 1800. Royal supremacy (Church of England)', 'Falkland, Henry Cary,',\n",
    "    'Viscount, d. 1633. Ireland', 'Cork (Ireland)', 'Fire, 1622', 'Liturgy. Church of Ireland', 'Ireland.', 'Poetry. Ballads, Irish', \n",
    "    \"O'Dogherty, Cahir,\", 'Malone, William, 1586-1656.']\n",
    "#portuguese_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20519ad3-bd1a-488b-9205-910649c08ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Neither': 264, 'Virginia': 46})\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "#targets counts relevant texts in the entire corpus\n",
    "targets = []\n",
    "#tcp_ids is a list of all texts that are in one of the target categories based off their metadata\n",
    "tcp_ids = set([])\n",
    "\n",
    "for key in keyword_dict.keys():\n",
    "    keywords = keyword_dict_prelim.get(key)\n",
    "    if any(k in virginia_terms for k in keywords):\n",
    "        targets.append('Virginia')\n",
    "        tcp_ids.add(key)\n",
    "    #elif any(k in spanish_terms for k in keywords):\n",
    "        #targets.append('Spanish')\n",
    "        tcp_ids.add(key)\n",
    "    #elif any(k in ireland_terms for k in keywords):\n",
    "        #targets.append(\"Ireland\")\n",
    "        tcp_ids.add(key)\n",
    "    #elif any(k in african_terms for k in keywords):\n",
    "        #targets.append(\"African\")\n",
    "        tcp_ids.add(key)\n",
    "    else:\n",
    "        targets.append('Neither')\n",
    "        tcp_ids.add(key)\n",
    "\n",
    "print(Counter(targets))\n",
    "print(len(tcp_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94836e4c-6f7f-472c-9d87-6739ec06576b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7857142857142857\n",
      "\n",
      "Results of this run:\n",
      "\n",
      "TCP ID | Actual Classfication | Predicted Classification\n",
      "A72111.txt | Neither | Neither\n",
      "A09493.txt | Neither | Neither\n",
      "A21455.txt | Neither | Neither\n",
      "A68944.txt | Neither | Neither\n",
      "A19590.txt | Neither | Neither\n",
      "B12610.txt | Neither | Neither\n",
      "A09295.txt | Neither | Neither\n",
      "A15357.txt | Neither | Neither\n",
      "B12998.txt | Neither | Neither\n",
      "A19864.txt | Neither | Neither\n",
      "A14526.txt | Neither | Neither\n",
      "A20435.txt | Virginia | Neither\n",
      "A22537.txt | Neither | Neither\n",
      "A04409.txt | Neither | Neither\n",
      "B14710.txt | Neither | Neither\n",
      "A08271.txt | Neither | Neither\n",
      "A03952.txt | Neither | Neither\n",
      "A22567.txt | Neither | Neither\n",
      "A08096.txt | Neither | Neither\n",
      "A09668.txt | Neither | Neither\n",
      "A73762.txt | Neither | Neither\n",
      "B12740.txt | Virginia | Neither\n",
      "A13959.txt | Virginia | Neither\n",
      "A16207.txt | Neither | Neither\n",
      "A01576.txt | Neither | Neither\n",
      "A14511.txt | Virginia | Neither\n",
      "B15880.txt | Virginia | Neither\n",
      "A17500.txt | Neither | Neither\n",
      "A22488.txt | Virginia | Neither\n",
      "A01580.txt | Neither | Neither\n",
      "A04899.txt | Neither | Neither\n",
      "A22156.txt | Neither | Neither\n",
      "A22441.txt | Neither | Neither\n",
      "A22439.txt | Neither | Neither\n",
      "A12676.txt | Neither | Neither\n",
      "A21067.txt | Virginia | Neither\n",
      "A22447.txt | Neither | Neither\n",
      "A22328.txt | Neither | Neither\n",
      "A07533.txt | Virginia | Neither\n",
      "B16236.txt | Virginia | Neither\n",
      "B07402.txt | Neither | Neither\n",
      "A02826.txt | Neither | Neither\n",
      "A08435.txt | Neither | Virginia\n",
      "A21698.txt | Neither | Neither\n",
      "A12949.txt | Neither | Neither\n",
      "A21877.txt | Virginia | Neither\n",
      "A02606.txt | Virginia | Neither\n",
      "A01948.txt | Neither | Neither\n",
      "A12466.txt | Neither | Neither\n",
      "A16912.txt | Neither | Neither\n",
      "A22321.txt | Virginia | Neither\n",
      "A22354.txt | Neither | Neither\n",
      "A01159.txt | Neither | Neither\n",
      "A20029.txt | Neither | Neither\n",
      "A19311.txt | Neither | Neither\n",
      "A14514.txt | Virginia | Neither\n",
      "A18465.txt | Neither | Neither\n",
      "A11213.txt | Virginia | Neither\n",
      "A07855.txt | Virginia | Neither\n",
      "A72113.txt | Neither | Neither\n",
      "A11788.txt | Neither | Neither\n",
      "A18210.txt | Neither | Neither\n",
      "A22435.txt | Neither | Neither\n",
      "A72336.txt | Neither | Neither\n",
      "B11752.txt | Neither | Neither\n",
      "A16245.txt | Neither | Neither\n",
      "A02049.txt | Virginia | Neither\n",
      "A06671.txt | Virginia | Neither\n",
      "A00983.txt | Neither | Neither\n",
      "A21879.txt | Neither | Neither\n",
      "A04630.txt | Neither | Neither\n",
      "A22250.txt | Neither | Neither\n",
      "A05339.txt | Neither | Neither\n",
      "A19312.txt | Neither | Neither\n",
      "A22440.txt | Neither | Neither\n",
      "A02655.txt | Neither | Neither\n",
      "A17485.txt | Neither | Neither\n",
      "A04104.txt | Neither | Neither\n",
      "A22696.txt | Virginia | Neither\n",
      "A13298.txt | Neither | Neither\n",
      "A04123.txt | Neither | Neither\n",
      "A14208.txt | Neither | Neither\n",
      "A11808.txt | Virginia | Neither\n",
      "A14338.txt | Neither | Neither\n",
      "A06083.txt | Neither | Neither\n",
      "A73138.txt | Neither | Neither\n",
      "A05412.txt | Neither | Neither\n",
      "A21490.txt | Neither | Neither\n",
      "A19341.txt | Neither | Neither\n",
      "A14958.txt | Neither | Neither\n",
      "A20838.txt | Neither | Neither\n",
      "A04106.txt | Neither | Neither\n",
      "A22364.txt | Neither | Virginia\n",
      "A20771.txt | Neither | Neither\n",
      "A22287.txt | Neither | Neither\n",
      "A22436.txt | Neither | Neither\n",
      "A20889.txt | Neither | Neither\n",
      "A01233.txt | Neither | Neither\n",
      "A16313.txt | Neither | Neither\n",
      "A18907.txt | Virginia | Neither\n",
      "B12757.txt | Neither | Neither\n",
      "A17512.txt | Neither | Neither\n",
      "A08107.txt | Neither | Neither\n",
      "A19439.txt | Neither | Neither\n",
      "A69361.txt | Neither | Neither\n",
      "A06803.txt | Neither | Neither\n",
      "A04713.txt | Neither | Neither\n",
      "A01503.txt | Virginia | Neither\n",
      "A08106.txt | Neither | Neither\n",
      "A14621.txt | Neither | Neither\n",
      "A02440.txt | Neither | Neither\n",
      "A08508.txt | Neither | Neither\n",
      "A11791.txt | Virginia | Neither\n",
      "B00838.txt | Neither | Neither\n",
      "A15097.txt | Neither | Neither\n",
      "A07832.txt | Virginia | Neither\n",
      "A73698.txt | Neither | Neither\n",
      "A14513.txt | Neither | Neither\n",
      "A12213.txt | Neither | Neither\n",
      "A22574.txt | Neither | Neither\n",
      "A04102.txt | Neither | Neither\n",
      "A04991.txt | Neither | Neither\n",
      "A18209.txt | Neither | Neither\n",
      "A12211.txt | Neither | Neither\n",
      "A08124.txt | Virginia | Neither\n",
      "B00675.txt | Neither | Neither\n",
      "A05165.txt | Neither | Neither\n",
      "A08571.txt | Virginia | Neither\n",
      "A11797.txt | Neither | Neither\n",
      "B15052.txt | Neither | Virginia\n",
      "A10713.txt | Neither | Neither\n",
      "A08102.txt | Neither | Neither\n",
      "A01444.txt | Neither | Neither\n",
      "A09559.txt | Neither | Neither\n",
      "A72801.txt | Neither | Neither\n",
      "A14615.txt | Virginia | Neither\n",
      "A04412.txt | Virginia | Neither\n",
      "A11246.txt | Neither | Neither\n",
      "A16507.txt | Neither | Neither\n",
      "A03116.txt | Neither | Neither\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(readable_results, targets, test_size=0.45, random_state=42)\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs', penalty='none', class_weight='balanced')\n",
    "clf = lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# evaluate accuracy\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred, normalize=True, sample_weight=None))\n",
    "print()\n",
    "print(\"Results of this run:\\n\")\n",
    "print(\"TCP ID | Actual Classfication | Predicted Classification\")\n",
    "for title, real, predicted in zip(X_test.index, y_test, y_pred):\n",
    "    print(f\"{title} | {real} | {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f6c1c02-2656-484c-ab2f-8a171af9729d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.4142857142857143\n",
      "\n",
      "Results of this run:\n",
      "\n",
      "TCP ID | Actual Classfication | Predicted Classification\n",
      "A72111.txt | Neither | Neither\n",
      "A09493.txt | Neither | Spanish\n",
      "A21455.txt | Neither | Neither\n",
      "A68944.txt | Neither | Neither\n",
      "A19590.txt | Neither | Neither\n",
      "B12610.txt | Neither | Neither\n",
      "A09295.txt | African | Neither\n",
      "A15357.txt | Neither | Neither\n",
      "B12998.txt | Neither | Neither\n",
      "A19864.txt | Spanish | Neither\n",
      "A14526.txt | Spanish | African\n",
      "A20435.txt | Virginia | Neither\n",
      "A22537.txt | Ireland | Spanish\n",
      "A04409.txt | Neither | Neither\n",
      "B14710.txt | Neither | Neither\n",
      "A08271.txt | Neither | Neither\n",
      "A03952.txt | Spanish | Spanish\n",
      "A22567.txt | Neither | Neither\n",
      "A08096.txt | Spanish | Neither\n",
      "A09668.txt | Spanish | Neither\n",
      "A73762.txt | Neither | Neither\n",
      "B12740.txt | Virginia | Neither\n",
      "A13959.txt | Virginia | Neither\n",
      "A16207.txt | African | Neither\n",
      "A01576.txt | Neither | Neither\n",
      "A14511.txt | Virginia | Neither\n",
      "B15880.txt | Virginia | Neither\n",
      "A17500.txt | Neither | Spanish\n",
      "A22488.txt | Virginia | Neither\n",
      "A01580.txt | Neither | Neither\n",
      "A04899.txt | Spanish | Neither\n",
      "A22156.txt | Spanish | Neither\n",
      "A22441.txt | Neither | Virginia\n",
      "A22439.txt | Neither | Neither\n",
      "A12676.txt | Ireland | Neither\n",
      "A21067.txt | Virginia | Neither\n",
      "A22447.txt | Spanish | Neither\n",
      "A22328.txt | Spanish | Neither\n",
      "A07533.txt | Virginia | Neither\n",
      "B16236.txt | Virginia | Neither\n",
      "B07402.txt | Neither | Neither\n",
      "A02826.txt | Spanish | Neither\n",
      "A08435.txt | Neither | Virginia\n",
      "A21698.txt | Neither | Neither\n",
      "A12949.txt | Ireland | Neither\n",
      "A21877.txt | Virginia | Neither\n",
      "A02606.txt | Virginia | Neither\n",
      "A01948.txt | Neither | Neither\n",
      "A12466.txt | African | Neither\n",
      "A16912.txt | Neither | Neither\n",
      "A22321.txt | Virginia | Neither\n",
      "A22354.txt | Spanish | Neither\n",
      "A01159.txt | Ireland | Neither\n",
      "A20029.txt | Neither | Neither\n",
      "A19311.txt | Neither | Neither\n",
      "A14514.txt | Virginia | Neither\n",
      "A18465.txt | Ireland | Neither\n",
      "A11213.txt | Virginia | Neither\n",
      "A07855.txt | Virginia | Neither\n",
      "A72113.txt | Spanish | Spanish\n",
      "A11788.txt | Neither | Neither\n",
      "A18210.txt | Ireland | Neither\n",
      "A22435.txt | Neither | Neither\n",
      "A72336.txt | Neither | Neither\n",
      "B11752.txt | Neither | Neither\n",
      "A16245.txt | Spanish | Neither\n",
      "A02049.txt | Virginia | Spanish\n",
      "A06671.txt | Virginia | Neither\n",
      "A00983.txt | Neither | Neither\n",
      "A21879.txt | Neither | Neither\n",
      "A04630.txt | Neither | Neither\n",
      "A22250.txt | Neither | Spanish\n",
      "A05339.txt | Spanish | Neither\n",
      "A19312.txt | Spanish | Neither\n",
      "A22440.txt | Spanish | Neither\n",
      "A02655.txt | Neither | Neither\n",
      "A17485.txt | Neither | Virginia\n",
      "A04104.txt | Neither | Neither\n",
      "A22696.txt | Virginia | Neither\n",
      "A13298.txt | Spanish | Neither\n",
      "A04123.txt | Neither | Neither\n",
      "A14208.txt | Neither | Neither\n",
      "A11808.txt | Virginia | Ireland\n",
      "A14338.txt | Neither | Neither\n",
      "A06083.txt | African | Neither\n",
      "A73138.txt | Neither | Neither\n",
      "A05412.txt | Ireland | Neither\n",
      "A21490.txt | Ireland | Neither\n",
      "A19341.txt | Neither | Neither\n",
      "A14958.txt | Neither | Neither\n",
      "A20838.txt | Spanish | Spanish\n",
      "A04106.txt | Neither | Neither\n",
      "A22364.txt | Neither | Virginia\n",
      "A20771.txt | Ireland | Ireland\n",
      "A22287.txt | Ireland | Neither\n",
      "A22436.txt | Ireland | Neither\n",
      "A20889.txt | Neither | African\n",
      "A01233.txt | Spanish | Neither\n",
      "A16313.txt | Neither | Neither\n",
      "A18907.txt | Virginia | Neither\n",
      "B12757.txt | Neither | Neither\n",
      "A17512.txt | Neither | Neither\n",
      "A08107.txt | Ireland | Neither\n",
      "A19439.txt | Spanish | Neither\n",
      "A69361.txt | Spanish | Neither\n",
      "A06803.txt | Neither | Neither\n",
      "A04713.txt | Neither | Spanish\n",
      "A01503.txt | Virginia | Neither\n",
      "A08106.txt | Neither | Neither\n",
      "A14621.txt | Neither | Neither\n",
      "A02440.txt | Neither | Spanish\n",
      "A08508.txt | African | Neither\n",
      "A11791.txt | Virginia | Neither\n",
      "B00838.txt | Spanish | Spanish\n",
      "A15097.txt | Spanish | Neither\n",
      "A07832.txt | Virginia | Neither\n",
      "A73698.txt | Neither | Spanish\n",
      "A14513.txt | Spanish | Neither\n",
      "A12213.txt | Neither | Neither\n",
      "A22574.txt | Neither | Neither\n",
      "A04102.txt | Ireland | Neither\n",
      "A04991.txt | Ireland | Neither\n",
      "A18209.txt | Neither | Neither\n",
      "A12211.txt | Neither | Neither\n",
      "A08124.txt | Virginia | Neither\n",
      "B00675.txt | Neither | Neither\n",
      "A05165.txt | Neither | Neither\n",
      "A08571.txt | Virginia | Neither\n",
      "A11797.txt | Neither | Neither\n",
      "B15052.txt | Ireland | Virginia\n",
      "A10713.txt | Spanish | Neither\n",
      "A08102.txt | Spanish | Spanish\n",
      "A01444.txt | Neither | Spanish\n",
      "A09559.txt | Ireland | Neither\n",
      "A72801.txt | Ireland | Neither\n",
      "A14615.txt | Virginia | Neither\n",
      "A04412.txt | Virginia | Neither\n",
      "A11246.txt | Neither | Neither\n",
      "A16507.txt | Ireland | Neither\n",
      "A03116.txt | Neither | Neither\n"
     ]
    }
   ],
   "source": [
    "#what about a naive bayes classifier? \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(readable_results, targets, test_size=0.45, random_state=42)\n",
    "gb = GaussianNB()\n",
    "clf = gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# evaluate accuracy\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred, normalize=True, sample_weight=None))\n",
    "print()\n",
    "print(\"Results of this run:\\n\")\n",
    "print(\"TCP ID | Actual Classfication | Predicted Classification\")\n",
    "for title, real, predicted in zip(X_test.index, y_test, y_pred):\n",
    "    print(f\"{title} | {real} | {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cb89d95-4490-4a55-a980-8f57618868b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.39285714285714285\n",
      "\n",
      "Results of this run:\n",
      "\n",
      "TCP ID | Actual Classfication | Predicted Classification\n",
      "A72111.txt | Neither | Neither\n",
      "A09493.txt | Neither | Neither\n",
      "A21455.txt | Neither | Neither\n",
      "A68944.txt | Neither | Neither\n",
      "A19590.txt | Neither | Neither\n",
      "B12610.txt | Neither | Neither\n",
      "A09295.txt | African | Neither\n",
      "A15357.txt | Neither | Neither\n",
      "B12998.txt | Neither | Neither\n",
      "A19864.txt | Spanish | Neither\n",
      "A14526.txt | Spanish | Neither\n",
      "A20435.txt | Virginia | Neither\n",
      "A22537.txt | Ireland | Neither\n",
      "A04409.txt | Neither | Neither\n",
      "B14710.txt | Neither | Neither\n",
      "A08271.txt | Neither | Neither\n",
      "A03952.txt | Spanish | Spanish\n",
      "A22567.txt | Neither | Neither\n",
      "A08096.txt | Spanish | Neither\n",
      "A09668.txt | Spanish | Neither\n",
      "A73762.txt | Neither | Neither\n",
      "B12740.txt | Virginia | Neither\n",
      "A13959.txt | Virginia | Neither\n",
      "A16207.txt | African | Neither\n",
      "A01576.txt | Neither | Neither\n",
      "A14511.txt | Virginia | Neither\n",
      "B15880.txt | Virginia | Neither\n",
      "A17500.txt | Neither | Neither\n",
      "A22488.txt | Virginia | Virginia\n",
      "A01580.txt | Neither | Neither\n",
      "A04899.txt | Spanish | Neither\n",
      "A22156.txt | Spanish | Spanish\n",
      "A22441.txt | Neither | Spanish\n",
      "A22439.txt | Neither | Neither\n",
      "A12676.txt | Ireland | Neither\n",
      "A21067.txt | Virginia | Neither\n",
      "A22447.txt | Spanish | Neither\n",
      "A22328.txt | Spanish | Neither\n",
      "A07533.txt | Virginia | Neither\n",
      "B16236.txt | Virginia | Neither\n",
      "B07402.txt | Neither | Neither\n",
      "A02826.txt | Spanish | Neither\n",
      "A08435.txt | Neither | Neither\n",
      "A21698.txt | Neither | Neither\n",
      "A12949.txt | Ireland | Ireland\n",
      "A21877.txt | Virginia | Neither\n",
      "A02606.txt | Virginia | Neither\n",
      "A01948.txt | Neither | Neither\n",
      "A12466.txt | African | Neither\n",
      "A16912.txt | Neither | Ireland\n",
      "A22321.txt | Virginia | Neither\n",
      "A22354.txt | Spanish | Neither\n",
      "A01159.txt | Ireland | Neither\n",
      "A20029.txt | Neither | Spanish\n",
      "A19311.txt | Neither | Neither\n",
      "A14514.txt | Virginia | Neither\n",
      "A18465.txt | Ireland | Virginia\n",
      "A11213.txt | Virginia | Spanish\n",
      "A07855.txt | Virginia | Neither\n",
      "A72113.txt | Spanish | Neither\n",
      "A11788.txt | Neither | Neither\n",
      "A18210.txt | Ireland | Neither\n",
      "A22435.txt | Neither | Neither\n",
      "A72336.txt | Neither | Neither\n",
      "B11752.txt | Neither | Ireland\n",
      "A16245.txt | Spanish | Neither\n",
      "A02049.txt | Virginia | Neither\n",
      "A06671.txt | Virginia | Ireland\n",
      "A00983.txt | Neither | Neither\n",
      "A21879.txt | Neither | Neither\n",
      "A04630.txt | Neither | Neither\n",
      "A22250.txt | Neither | Neither\n",
      "A05339.txt | Spanish | Neither\n",
      "A19312.txt | Spanish | Neither\n",
      "A22440.txt | Spanish | Neither\n",
      "A02655.txt | Neither | Neither\n",
      "A17485.txt | Neither | Virginia\n",
      "A04104.txt | Neither | Neither\n",
      "A22696.txt | Virginia | Neither\n",
      "A13298.txt | Spanish | Neither\n",
      "A04123.txt | Neither | Neither\n",
      "A14208.txt | Neither | Neither\n",
      "A11808.txt | Virginia | Neither\n",
      "A14338.txt | Neither | Neither\n",
      "A06083.txt | African | Neither\n",
      "A73138.txt | Neither | Neither\n",
      "A05412.txt | Ireland | Neither\n",
      "A21490.txt | Ireland | Neither\n",
      "A19341.txt | Neither | Neither\n",
      "A14958.txt | Neither | Neither\n",
      "A20838.txt | Spanish | Neither\n",
      "A04106.txt | Neither | Spanish\n",
      "A22364.txt | Neither | Neither\n",
      "A20771.txt | Ireland | Neither\n",
      "A22287.txt | Ireland | Neither\n",
      "A22436.txt | Ireland | Neither\n",
      "A20889.txt | Neither | Spanish\n",
      "A01233.txt | Spanish | Neither\n",
      "A16313.txt | Neither | Neither\n",
      "A18907.txt | Virginia | Virginia\n",
      "B12757.txt | Neither | Neither\n",
      "A17512.txt | Neither | Neither\n",
      "A08107.txt | Ireland | Neither\n",
      "A19439.txt | Spanish | Neither\n",
      "A69361.txt | Spanish | Neither\n",
      "A06803.txt | Neither | Virginia\n",
      "A04713.txt | Neither | Ireland\n",
      "A01503.txt | Virginia | Neither\n",
      "A08106.txt | Neither | Neither\n",
      "A14621.txt | Neither | Virginia\n",
      "A02440.txt | Neither | Spanish\n",
      "A08508.txt | African | Neither\n",
      "A11791.txt | Virginia | Neither\n",
      "B00838.txt | Spanish | Neither\n",
      "A15097.txt | Spanish | Neither\n",
      "A07832.txt | Virginia | Neither\n",
      "A73698.txt | Neither | Spanish\n",
      "A14513.txt | Spanish | Neither\n",
      "A12213.txt | Neither | Neither\n",
      "A22574.txt | Neither | Neither\n",
      "A04102.txt | Ireland | Neither\n",
      "A04991.txt | Ireland | Neither\n",
      "A18209.txt | Neither | Neither\n",
      "A12211.txt | Neither | Neither\n",
      "A08124.txt | Virginia | Neither\n",
      "B00675.txt | Neither | Neither\n",
      "A05165.txt | Neither | Neither\n",
      "A08571.txt | Virginia | Ireland\n",
      "A11797.txt | Neither | Neither\n",
      "B15052.txt | Ireland | Neither\n",
      "A10713.txt | Spanish | Neither\n",
      "A08102.txt | Spanish | Neither\n",
      "A01444.txt | Neither | Spanish\n",
      "A09559.txt | Ireland | Neither\n",
      "A72801.txt | Ireland | Neither\n",
      "A14615.txt | Virginia | Neither\n",
      "A04412.txt | Virginia | Neither\n",
      "A11246.txt | Neither | Spanish\n",
      "A16507.txt | Ireland | Neither\n",
      "A03116.txt | Neither | Neither\n"
     ]
    }
   ],
   "source": [
    "#k-nearest neighbors?\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#ask giugni about k-nearest neighbor \n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(readable_results, targets, test_size=0.45, random_state=42)\n",
    "clf = knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# evaluate accuracy\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred, normalize=True, sample_weight=None))\n",
    "print()\n",
    "print(\"Results of this run:\\n\")\n",
    "print(\"TCP ID | Actual Classfication | Predicted Classification\")\n",
    "for title, real, predicted in zip(X_test.index, y_test, y_pred):\n",
    "    print(f\"{title} | {real} | {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23faed-c969-4f6a-b23c-225704fcb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and move subcorpuses \n",
    "def move_subcorpus(id_list):\n",
    "    for file in os.scandir(r\"/hpc/group/datap2023ecbc/lemmatized_without_stop\"):\n",
    "        name = os.path.basename(file).split(\".\")[0]\n",
    "        if name in id_list:\n",
    "            with open(file, encoding=\"utf-8\") as EPextracted:\n",
    "                #remember to put the correct pathway for output and input! based off of what you are trying\n",
    "                #to understand!\n",
    "                with open(os.path.join(r\"/hpc/group/datap2023ecbc/virginia_subcorpus\", name), 'w+') as lowerFile:\n",
    "                    data = EPextracted.read()\n",
    "                    lowerFile.write(data.lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
