{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14d2ecab-31bc-40bc-8369-9c30b2829dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /hpc/home/sek45/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What texts would you like to use? (file directory):  /hpc/group/datap2023ecbc/Time Series Modeling Ranges/1610-1619_texts\n"
     ]
    }
   ],
   "source": [
    "\"\"\"author: sarah konrad, data+ 2023\n",
    "create lda topic modeling clusters on our corpus!\n",
    "\"\"\"\n",
    "import os\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#converts texts into a master list of lists of strings (needed for BOW)\n",
    "def textstolist(folder): \n",
    "    texts = []\n",
    "    for file in os.scandir(folder):\n",
    "        path = os.path.join(folder,file)\n",
    "        name = os.path.basename(file)\n",
    "        f = open(path,'r', encoding=\"utf-8\")\n",
    "        data = f.read()\n",
    "        texts.append(data)\n",
    "        f.close()\n",
    "    textlists = []\n",
    "    for text in texts: \n",
    "        text = text.split(\" \")\n",
    "        textlists.append(text)\n",
    "    return textlists\n",
    "\n",
    "processed_texts = textstolist(input(\"What texts would you like to use? (file directory): \"))\n",
    "tokendict = gensim.corpora.Dictionary(processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "716ad36c-8857-489c-9419-79ed0fc59c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ^ll\n",
      "1 alarm\n",
      "2 barrel\n",
      "3 bleed\n",
      "4 bound\n",
      "5 britain\n",
      "6 broil\n",
      "7 castle\n",
      "8 claim\n",
      "9 commodity\n",
      "10 consequence\n",
      "16547\n"
     ]
    }
   ],
   "source": [
    "#for testing functionality of the dictionary being built for topic modeling\n",
    "count = 0\n",
    "for key, value in tokendict.iteritems():\n",
    "    print(key, value)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "\n",
    "print(len(tokendict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "667e7fdd-9c73-4374-92a4-716d6d4cc1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.005*\"affliction\" + 0.002*\"meditation\" + 0.002*\"temptation\" + 0.002*\"humility\" + 0.002*\"chap\" + 0.002*\"righteousness\" + 0.002*\"sect\" + 0.002*\"accord\" + 0.002*\"prosperity\" + 0.002*\"poverty\"\n",
      "Topic: 1 \n",
      "Words: 0.006*\"fortune\" + 0.004*\"quote\" + 0.003*\"amadis\" + 0.003*\"fame\" + 0.003*\"greek\" + 0.003*\"ere\" + 0.002*\"brave\" + 0.002*\"foe\" + 0.002*\"oft\" + 0.002*\"chance\"\n",
      "Topic: 2 \n",
      "Words: 0.007*\"hawk\" + 0.006*\"chap\" + 0.005*\"angle\" + 0.004*\"oil\" + 0.004*\"quantity\" + 0.004*\"leg\" + 0.004*\"figure\" + 0.004*\"medicine\" + 0.003*\"leaf\" + 0.003*\"boil\"\n",
      "Topic: 3 \n",
      "Words: 0.016*\"bishop\" + 0.013*\"pope\" + 0.011*\"catholic\" + 0.007*\"temporal\" + 0.006*\"protestant\" + 0.006*\"augustine\" + 0.006*\"doctor\" + 0.006*\"council\" + 0.005*\"bellarmine\" + 0.005*\"adversary\"\n",
      "Topic: 4 \n",
      "Words: 0.019*\"earl\" + 0.014*\"henry\" + 0.012*\"duke\" + 0.009*\"edward\" + 0.007*\"william\" + 0.007*\"britain\" + 0.007*\"london\" + 0.006*\"richard\" + 0.005*\"french\" + 0.005*\"castle\"\n",
      "Topic: 5 \n",
      "Words: 0.018*\"muscle\" + 0.018*\"castile\" + 0.015*\"vein\" + 0.014*\"fig\" + 0.011*\"artery\" + 0.011*\"navarre\" + 0.010*\"aragon\" + 0.010*\"tab\" + 0.009*\"moor\" + 0.009*\"brain\"\n",
      "Topic: 6 \n",
      "Words: 0.011*\"army\" + 0.007*\"venetian\" + 0.007*\"emperor\" + 0.007*\"captain\" + 0.006*\"duke\" + 0.006*\"league\" + 0.005*\"island\" + 0.005*\"pope\" + 0.005*\"spain\" + 0.005*\"turk\"\n",
      "Topic: 7 \n",
      "Words: 0.031*\"pope\" + 0.020*\"bishop\" + 0.014*\"emperor\" + 0.010*\"council\" + 0.006*\"tithe\" + 0.006*\"cardinal\" + 0.005*\"antichrist\" + 0.005*\"canon\" + 0.005*\"empire\" + 0.005*\"epistle\"\n",
      "Topic: 8 \n",
      "Words: 0.012*\"sacrament\" + 0.011*\"righteousness\" + 0.009*\"tim\" + 0.009*\"baptism\" + 0.007*\"covenant\" + 0.006*\"heb\" + 0.005*\"gentile\" + 0.005*\"abraham\" + 0.005*\"baptize\" + 0.005*\"justification\"\n",
      "Topic: 9 \n",
      "Words: 0.005*\"job\" + 0.004*\"daniel\" + 0.004*\"sam\" + 0.004*\"chap\" + 0.004*\"abraham\" + 0.004*\"righteousness\" + 0.003*\"righteous\" + 0.003*\"chapter\" + 0.003*\"jacob\" + 0.003*\"tim\"\n"
     ]
    }
   ],
   "source": [
    "#remove tokens that appear in less than 15 texts, more than 0.5 documents\n",
    "#keep 100,000 most frequent tokens\n",
    "#this step helps improve the accuracy of topic modeling by removing irrelevant terms!\n",
    "tokendict.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "#transform into bag o' words\n",
    "bagofwords_corpus = [tokendict.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "#now run tf-idf on the bag of words to see how relevant terms are to the entire corpus!!\n",
    "#note to self: perhaps add a functionality that maps the tf-idf score of a word to the word in a dictionary \n",
    "\n",
    "tfidf_model = models.TfidfModel(bagofwords_corpus)\n",
    "corpus_tfidf = tfidf_model[bagofwords_corpus]\n",
    "\n",
    "#train and obtain output from the lda model\n",
    "lda_model = gensim.models.LdaMulticore(bagofwords_corpus, num_topics=10, id2word=tokendict, passes=20, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44031f6c-0d76-4e59-8beb-a268e013d3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Word: 0.004*\"realm\" + 0.003*\"proclamation\" + 0.003*\"london\" + 0.003*\"highness\" + 0.002*\"earl\" + 0.002*\"tobacco\" + 0.002*\"muse\" + 0.002*\"quote\" + 0.002*\"fate\" + 0.002*\"westminster\"\n",
      "Topic: 1 \n",
      "Word: 0.001*\"andrews\" + 0.000*\"harper\" + 0.000*\"alva\" + 0.000*\"maxwell\" + 0.000*\"flushing\" + 0.000*\"staple\" + 0.000*\"marinus\" + 0.000*\"rog\" + 0.000*\"ptolomey\" + 0.000*\"converter\"\n",
      "Topic: 2 \n",
      "Word: 0.002*\"pope\" + 0.001*\"righteousness\" + 0.001*\"bishop\" + 0.001*\"sacrament\" + 0.001*\"chap\" + 0.001*\"catholic\" + 0.001*\"job\" + 0.001*\"heb\" + 0.001*\"affliction\" + 0.001*\"righteous\"\n",
      "Topic: 3 \n",
      "Word: 0.002*\"epig\" + 0.001*\"balsam\" + 0.000*\"quint\" + 0.000*\"te\" + 0.000*\"mets\" + 0.000*\"plane\" + 0.000*\"ang\" + 0.000*\"commoner\" + 0.000*\"astronomical\" + 0.000*\"semidiameter\"\n",
      "Topic: 4 \n",
      "Word: 0.001*\"martini\" + 0.001*\"thais\" + 0.001*\"downam\" + 0.001*\"cromwell\" + 0.001*\"felt\" + 0.000*\"marg\" + 0.000*\"eustace\" + 0.000*\"bavier\" + 0.000*\"barcelona\" + 0.000*\"sophronius\"\n",
      "Topic: 5 \n",
      "Word: 0.001*\"hugh\" + 0.000*\"cullen\" + 0.000*\"shy\" + 0.000*\"quadrant\" + 0.000*\"coniug\" + 0.000*\"princ\" + 0.000*\"opt\" + 0.000*\"tri\" + 0.000*\"sor\" + 0.000*\"coventrie\"\n",
      "Topic: 6 \n",
      "Word: 0.001*\"gar\" + 0.000*\"welt\" + 0.000*\"sub\" + 0.000*\"goodwife\" + 0.000*\"bailie\" + 0.000*\"pri\" + 0.000*\"aa\" + 0.000*\"burgh\" + 0.000*\"octavio\" + 0.000*\"mustapha\"\n",
      "Topic: 7 \n",
      "Word: 0.002*\"lottery\" + 0.001*\"chart\" + 0.001*\"sub\" + 0.001*\"breton\" + 0.001*\"drury\" + 0.000*\"tyne\" + 0.000*\"alb\" + 0.000*\"hereunder\" + 0.000*\"candlemas\" + 0.000*\"sur\"\n",
      "Topic: 8 \n",
      "Word: 0.001*\"ignatian\" + 0.001*\"peloponnesus\" + 0.001*\"sarum\" + 0.001*\"morgan\" + 0.001*\"testimonial\" + 0.000*\"product\" + 0.000*\"sur\" + 0.000*\"exportation\" + 0.000*\"quadrate\" + 0.000*\"oxon\"\n",
      "Topic: 9 \n",
      "Word: 0.002*\"amadis\" + 0.001*\"arb\" + 0.001*\"colloquy\" + 0.000*\"pisa\" + 0.000*\"lucia\" + 0.000*\"br\" + 0.000*\"gaoler\" + 0.000*\"com\" + 0.000*\"heigh\" + 0.000*\"do^\"\n"
     ]
    }
   ],
   "source": [
    "#run it with tfidf\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=tokendict, passes=20, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWord: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ecc02-f5b0-4067-acdb-e72a60568110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
