{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "342aecf1-029a-46e4-aec1-519cb39210f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from gensim.models import Phrases, phrases\n",
    "\n",
    "def getTexts(folder):\n",
    "    fileToText = {}\n",
    "    underscores = {}\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "                if '.txt' not in file: continue\n",
    "                path = os.path.join(folder,file)\n",
    "                f = open(path,'r',errors=\"ignore\")\n",
    "                text = f.read()\n",
    "                name = file.split('.')[0]\n",
    "                fileToText[name] = text\n",
    "                f.close()\n",
    "        return fileToText\n",
    "\n",
    "def collectgrams(keylist, searchword, collectlist):\n",
    "        for key in keylist:\n",
    "                if searchword in key.split('_'):\n",
    "                        collectlist.append(key) \n",
    "\n",
    "def getgrams(txt):\n",
    "    infile = open(txt,'r')\n",
    "    lines = infile.readlines()\n",
    "    infile.close()\n",
    "    allgrams = []\n",
    "    for line in lines: \n",
    "        line = line.split(':')\n",
    "        ngrams = line[1].strip()\n",
    "        if '_' in ngrams: \n",
    "                ngrams = ngrams.strip().split(' ')\n",
    "                for n in ngrams:\n",
    "                        allgrams.append(n)\n",
    "        else: continue\n",
    "    return allgrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a13cf91b-9940-40e6-9658-7bbf39cdede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n"
     ]
    }
   ],
   "source": [
    "bigramdata = getTexts('/hpc/group/datap2023ecbc/Time Series Modeling Ranges/1636-1639_texts')\n",
    "bigramtexts = list(bigramdata.values())\n",
    "bigramnames = list(bigramdata.keys())\n",
    "print(len(bigramnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "321331d5-a064-4902-8cb4-de92e3ed504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n",
      "bigram model trained\n",
      "trigram model trained\n"
     ]
    }
   ],
   "source": [
    "training = []\n",
    "for t in bigramtexts:\n",
    "    words = t.split(' ')\n",
    "    training.append(words)\n",
    "\n",
    "print(len(training))\n",
    "bigrammodel = Phrases(training, min_count=3, threshold= 0, scoring='npmi', connector_words=phrases.ENGLISH_CONNECTOR_WORDS, max_vocab_size =100000000)\n",
    "print('bigram model trained')\n",
    "\n",
    "trigrammodel = Phrases(bigrammodel[training], min_count=2, threshold= 0, scoring='npmi', connector_words=phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "print('trigram model trained')\n",
    "\n",
    "total_bigram = bigrammodel.__dict__  # Get the model parameters as a dictionary\n",
    "total_trigram = trigrammodel.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4fd6fa7e-978e-4a73-adf9-0166070fba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800813\n"
     ]
    }
   ],
   "source": [
    "# combine bigram & trigram dictionary\n",
    "if total_bigram and total_trigram:\n",
    "    total_gram = {**total_bigram, **total_trigram}\n",
    "\n",
    "# The output of the phrase model is a nested dictionary, \n",
    "# and all we need is the value of key=vocab\n",
    "gram_dict = total_gram['vocab']\n",
    "# with the line below to filter the grams by their frequency\n",
    "filtered_dict = {key: value for key, value in gram_dict.items() if value > 1}\n",
    "# the size of the grams in this folder\n",
    "print(len(filtered_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "285ebbd0-133c-4fad-953f-2b4a88c55723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "#specify searchwordï¼š\n",
    "searchwords = ['spanish']\n",
    "searchword_keys = []\n",
    "\n",
    "count = 0\n",
    "with open('/hpc/group/datap2023ecbc/Ngrams_Spanish/Ngrams_1636_1639.txt', 'w') as file:\n",
    "  \n",
    "    # for key,value in filtered_dict.items():\n",
    "    for searchword in searchwords: \n",
    "        collectgrams(filtered_dict.keys(), searchword, searchword_keys)\n",
    "    print(len(searchword_keys))\n",
    "    \n",
    "# iterate the searchword_keys (a list), \n",
    "# each element in it is a N-gram word pair,\n",
    "# write the N-gram with its freq(find it in the filtered_dict)\n",
    "    for i,element in enumerate(searchword_keys):\n",
    "        k = searchword_keys[i]\n",
    "        freq = filtered_dict[k]\n",
    "        file.write(f'{k}: {freq}\\n')\n",
    "            # print(k + ':'+ str(filtered_dict[k]))\n",
    "        count +=1\n",
    "        if count%500 == 0:\n",
    "            print(count,\"gram processed\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f1757693-496c-4b0d-96c9-5502a13154ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 files processed\n",
      "100 files processed\n",
      "150 files processed\n",
      "200 files processed\n",
      "250 files processed\n",
      "300 files processed\n",
      "350 files processed\n",
      "400 files processed\n",
      "450 files processed\n",
      "500 files processed\n",
      "550 files processed\n",
      "600 files processed\n",
      "650 files processed\n",
      "700 files processed\n",
      "750 files processed\n",
      "processing complete\n",
      "                    bigram frequency\n",
      "highness_quarter                   3\n",
      "run_approach                       2\n",
      "count_harrie                       2\n",
      "count_harry                        2\n",
      "count_william                      2\n",
      "high_towards                       2\n",
      "arable_land                        1\n",
      "pleasure_take                      1\n",
      "enemy_march                        1\n",
      "several_quarter                    1\n",
      "english_french                     1\n",
      "lieutenant_colonel                 1\n",
      "quarter_side                       1\n",
      "count_solmes                       1\n",
      "quarter_colonel                    1\n",
      "keep_enemy                         1\n",
      "french_english                     1\n",
      "approach_right                     1\n",
      "left_hand                          1\n",
      "french_approach                    1\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [trigram frequency]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "outfile = open('/hpc/group/datap2023ecbc/Ngrams_Spanish/Ngrams_Spanish_1636_1639.txt', 'w')\n",
    "for text in bigramtexts:\n",
    "    #for outputting to txt file, specify here\n",
    "    name = bigramnames[bigramtexts.index(text)]\n",
    "    testtext = text.strip().split(' ')\n",
    "    grams = []\n",
    "\n",
    "    bgcount = Counter(b for b in bigrammodel[testtext] if len(b.split(\"_\")) > 1)\n",
    "    tgcount = Counter(t for t in trigrammodel[testtext] if len(t.split(\"_\")) > 2)\n",
    "    filtered_bgcount = {key: value for key, value in dict(bgcount).items() if value > 1}\n",
    "    filtered_tgcount = {key: value for key, value in dict(tgcount).items() if value > 1}\n",
    "    \n",
    "    for searchword in searchwords: \n",
    "        collectgrams(filtered_bgcount.keys(), searchword, grams) \n",
    "        collectgrams(filtered_tgcount.keys(), searchword, grams)\n",
    "    \n",
    "    gramstring = ' '.join(grams)\n",
    "    outfile.write(name+': '+gramstring+\"\\n\")\n",
    "    count += 1\n",
    "    if count%50 == 0:\n",
    "        print(count, \"files processed\")\n",
    "outfile.close()\n",
    "print('processing complete')\n",
    "print(pd.DataFrame(dict(bgcount).values(), index=dict(bgcount).keys(), columns=['bigram frequency']).sort_values('bigram frequency', ascending=False).head(n=20))\n",
    "print(\"\\n\")\n",
    "print(pd.DataFrame(dict(tgcount).values(), index=dict(tgcount).keys(), columns=['trigram frequency']).sort_values('trigram frequency', ascending=False).head(n=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f640459-1554-4cfd-b747-3b563eb97398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
